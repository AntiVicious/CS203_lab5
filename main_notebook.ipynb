{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: augly in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: iopath>=0.1.8 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from augly) (0.1.10)\n",
      "Requirement already satisfied: python-magic>=0.4.22 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from augly) (0.4.27)\n",
      "Requirement already satisfied: regex>=2021.4.4 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from augly) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from iopath>=0.1.8->augly) (4.66.4)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from iopath>=0.1.8->augly) (4.12.2)\n",
      "Requirement already satisfied: portalocker in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from iopath>=0.1.8->augly) (3.1.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from portalocker->iopath>=0.1.8->augly) (305.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from tqdm->iopath>=0.1.8->augly) (0.4.6)\n",
      "Requirement already satisfied: nlpaug in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.16.2 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from nlpaug) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2.0 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from nlpaug) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.22.0 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from nlpaug) (2.32.3)\n",
      "Requirement already satisfied: gdown>=4.0.0 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from nlpaug) (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.12.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2022.7.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from pandas>=1.2.0->nlpaug) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests>=2.22.0->nlpaug) (2024.8.30)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.2.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from tqdm->gdown>=4.0.0->nlpaug) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade augly\n",
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training samples are 112\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import augly.image as imaugs\n",
    "import augly.utils as utils\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define dataset paths\n",
    "DATASET_PATH = \"dataset\"\n",
    "TRAIN_PATH = \"Train\"\n",
    "TEST_PATH = \"Test\"\n",
    "AUGMENTED_TRAIN_PATH = \"Aug_train\"\n",
    "\n",
    "# Create train and test directories\n",
    "os.makedirs(TRAIN_PATH, exist_ok=True)\n",
    "os.makedirs(TEST_PATH, exist_ok=True)\n",
    "os.makedirs(AUGMENTED_TRAIN_PATH, exist_ok=True)\n",
    "\n",
    "# Load image paths\n",
    "image_paths = glob.glob(os.path.join(DATASET_PATH, \"*.jpg\"))\n",
    "\n",
    "# Extract labels from filenames\n",
    "cats = [path for path in image_paths if \"cat\" in os.path.basename(path)]\n",
    "dogs = [path for path in image_paths if \"dog\" in os.path.basename(path)]\n",
    "\n",
    "# Ensure equal distribution in training set\n",
    "\n",
    "cats_train, cats_test = train_test_split(cats, test_size=0.2, random_state=1)\n",
    "dogs_train, dogs_test = train_test_split(dogs, test_size=0.2, random_state=1)\n",
    "\n",
    "train_paths = cats_train + dogs_train\n",
    "test_paths = cats_test + dogs_test\n",
    "train_labels = [\"cat\"] * len(cats_train) + [\"dog\"] * len(dogs_train)\n",
    "test_labels = [\"cat\"] * len(cats_test) + [\"dog\"] * len(dogs_test)\n",
    "\n",
    "# Move images to respective directories\n",
    "def move_files(file_paths, labels, destination):\n",
    "    for file_path, label in zip(file_paths, labels):\n",
    "        label_path = os.path.join(destination, label)\n",
    "        os.makedirs(label_path, exist_ok=True)\n",
    "        shutil.copy(file_path, os.path.join(label_path, os.path.basename(file_path)))\n",
    "\n",
    "move_files(train_paths, train_labels, TRAIN_PATH)\n",
    "move_files(train_paths, train_labels, AUGMENTED_TRAIN_PATH)\n",
    "move_files(test_paths, test_labels, TEST_PATH)\n",
    "\n",
    "print('total training samples are', len(train_paths))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Statistics:\n",
      "Original Train Set: 112\n",
      "Augmented Train Set: 224\n",
      "Final Train Set (Original + Augmented): 336\n",
      "Test Set: 28\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation function\n",
    "# Define augmentation function\n",
    "def augment_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    augmentations = [\n",
    "        imaugs.Rotate(degrees=random.uniform(-30, 30)),\n",
    "        imaugs.Blur(radius=random.uniform(1, 3)),\n",
    "        imaugs.Crop(random.uniform(0.1, 0.3)),\n",
    "        imaugs.Sharpen(factor=random.uniform(1.5, 2.5)),\n",
    "        imaugs.Brightness(factor=random.uniform(0.5, 1.5)),\n",
    "        imaugs.Contrast(factor=random.uniform(0.5, 1.5)),\n",
    "        imaugs.Saturation(factor=random.uniform(0.5, 1.5)),\n",
    "        imaugs.Pixelization(ratio=random.uniform(0.1, 0.3)),\n",
    "    ]\n",
    "    \n",
    "    augmented_images = []\n",
    "    for _ in range(2):  # Generate twice the train set size\n",
    "        random.shuffle(augmentations)  # Ensure different sequence\n",
    "        aug_pipeline = imaugs.Compose(augmentations[:3])  # Select 3 random augmentations\n",
    "        augmented_image = aug_pipeline(image)\n",
    "        augmented_images.append(augmented_image)\n",
    "    \n",
    "    return augmented_images\n",
    "\n",
    "# Augment the train set\n",
    "train_images = glob.glob(os.path.join(AUGMENTED_TRAIN_PATH, \"*/*.jpg\"))\n",
    "\n",
    "for img_path in train_images:\n",
    "    label = \"cat\" if \"cat\" in os.path.basename(img_path) else \"dog\"\n",
    "    augmented_images = augment_image(img_path)\n",
    "    base_name = os.path.basename(img_path).split(\".\")[0]\n",
    "    \n",
    "    label_dir = os.path.join(AUGMENTED_TRAIN_PATH, label)  # Save augmented images in train set\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "    \n",
    "    for idx, aug_img in enumerate(augmented_images):\n",
    "        save_path = os.path.join(label_dir, f\"{base_name}_aug{idx}.jpg\")\n",
    "        aug_img.save(save_path)\n",
    "\n",
    "# Dataset statistics\n",
    "original_train_count = len(train_images)\n",
    "augmented_train_count = len(glob.glob(os.path.join(AUGMENTED_TRAIN_PATH, \"*/*.jpg\"))) - original_train_count\n",
    "test_count = len(glob.glob(os.path.join(TEST_PATH, \"*/*.jpg\")))\n",
    "\n",
    "dataset_stats = {\n",
    "    \"Original Train Set\": original_train_count,\n",
    "    \"Augmented Train Set\": augmented_train_count,\n",
    "    \"Final Train Set (Original + Augmented)\": original_train_count + augmented_train_count,\n",
    "    \"Test Set\": test_count\n",
    "}\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "for key, value in dataset_stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "     ---------------------------------------- 0.0/44.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 44.4/44.4 kB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\pmaha\\anaconda3\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "   ---------------------------------------- 0.0/9.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/9.7 MB 2.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.4/9.7 MB 4.2 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 0.9/9.7 MB 6.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.4/9.7 MB 7.6 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 1.8/9.7 MB 7.8 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.3/9.7 MB 8.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 2.8/9.7 MB 8.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 3.6/9.7 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 4.4/9.7 MB 10.4 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.2/9.7 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 6.2/9.7 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 6.8/9.7 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 7.5/9.7 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 8.4/9.7 MB 12.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 9.3/9.7 MB 13.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.7/9.7 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.7/9.7 MB 12.4 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "   ---------------------------------------- 0.0/464.1 kB ? eta -:--:--\n",
      "   --------------------------------------- 464.1/464.1 kB 14.6 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "   ---------------------------------------- 0.0/303.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 303.8/303.8 kB 19.6 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 0.9/2.4 MB 20.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.8/2.4 MB 19.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 17.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.28.1 safetensors-0.5.2 tokenizers-0.21.0 transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-50 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([2]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 2048]) in the checkpoint and torch.Size([2, 2048]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\pmaha\\anaconda3\\Lib\\site-packages\\transformers\\models\\convnext\\feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForImageClassification, AutoFeatureExtractor\n",
    "import torch\n",
    "\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "\n",
    "# Load the pre-trained model with randomly initialized weights\n",
    "model = AutoModelForImageClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "model_aug = AutoModelForImageClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import glob\n",
    "\n",
    "# Define transforms (resize images to match ResNet-50 input size)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Required for ResNet-50\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "])\n",
    "\n",
    "class DogsCatsDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        label = 0 if \"cat\" in self.image_paths[idx] else 1  # 0 for cats, 1 for dogs\n",
    "        return image, label\n",
    "\n",
    "# Load train and test images\n",
    "train_images = glob.glob(\"Train/*/*.jpg\")\n",
    "aug_train_images = glob.glob(\"Aug_train/*/*.jpg\")\n",
    "test_images = glob.glob(\"Test/*/*.jpg\")\n",
    "\n",
    "train_labels = [0 if \"cat\" in img else 1 for img in train_images]\n",
    "aug_train_labels = [0 if \"cat\" in img else 1 for img in aug_train_images]\n",
    "test_labels = [0 if \"cat\" in img else 1 for img in test_images]\n",
    "\n",
    "# Create datasets and dataloaders\n",
    "train_dataset = DogsCatsDataset(train_images, train_labels, transform)\n",
    "aug_train_dataset = DogsCatsDataset(aug_train_images, aug_train_labels, transform)\n",
    "test_dataset = DogsCatsDataset(test_images, test_labels, transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "aug_train_loader = DataLoader(aug_train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6914\n",
      "Epoch 2/10, Loss: 0.6617\n",
      "Epoch 3/10, Loss: 0.6348\n",
      "Epoch 4/10, Loss: 0.6162\n",
      "Epoch 5/10, Loss: 0.5877\n",
      "Epoch 6/10, Loss: 0.5702\n",
      "Epoch 7/10, Loss: 0.5389\n",
      "Epoch 8/10, Loss: 0.5068\n",
      "Epoch 9/10, Loss: 0.4876\n",
      "Epoch 10/10, Loss: 0.4677\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.4762\n",
      "Epoch 2/10, Loss: 1.4647\n",
      "Epoch 3/10, Loss: 1.4870\n",
      "Epoch 4/10, Loss: 1.4700\n",
      "Epoch 5/10, Loss: 1.4646\n",
      "Epoch 6/10, Loss: 1.4756\n",
      "Epoch 7/10, Loss: 1.4750\n",
      "Epoch 8/10, Loss: 1.4716\n",
      "Epoch 9/10, Loss: 1.4711\n",
      "Epoch 10/10, Loss: 1.4884\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_aug.to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model_aug.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model_aug.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for images, labels in aug_train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images).logits\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8214\n",
      "Precision: 1.0000\n",
      "Recall: 0.6429\n",
      "F1 Score: 0.7826\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "model.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5000\n",
      "Precision: 0.5000\n",
      "Recall: 0.3571\n",
      "F1 Score: 0.4167\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "model_aug.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model_aug(images).logits\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Compute metrics\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision = precision_score(all_labels, all_preds)\n",
    "recall = recall_score(all_labels, all_preds)\n",
    "f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
